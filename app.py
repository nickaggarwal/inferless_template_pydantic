import json
import os
import numpy as np
import torch
from transformers import pipeline
from datetime import datetime

import inferless
from pydantic import BaseModel, Field
from typing import List, Optional, Dict

@inferless.request
class RequestObjects(BaseModel):
    input_image_url: str = Field(default='https://hello.world')
    count_iterations: int = Field(default=4)
    prompt: str = Field(default="a horse near a beach")
    mask_arr: List[int] = Field(default=[1, 5])
    is_aws: Optional[bool] = None


@inferless.response
class ResponseObjects(BaseModel):
    output_image_url: str
    count_iterations: int
    quality: float
    positions: List[int] = Field(default=[1, 5])
    is_aws: Optional[float] = None

class InferlessPythonModel:

    # replace ##task_type## and ##huggingface_name## with appropriate values
    def initialize(self):
        self.generator = pipeline("text-generation", model="EleutherAI/gpt-neo-125M",device=0)

    # inputs is a dictonary where the keys are input names and values are actual input data
    # e.g. in the below code the input name is prompt 
    # The output generated by the infer function should be a dictonary where keys are output names and values are actual output data
    # e.g. in the below code the output name is generated_txt
    def infer(self, inputs):
        print("we came inside infer", flush=True)
        prompt = inputs["prompt"]
        pipeline_output = self.generator(prompt, do_sample=True, min_length=50)
        generated_txt = pipeline_output[0]["generated_text"]
        return {"generated_text": generated_txt }

    # perform any cleanup activity here
    def finalize(self,args):
        self.pipe = None
