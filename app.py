import torch
from transformers import pipeline
from datetime import datetime

import inferless
from pydantic import BaseModel, Field
from typing import List, Optional, Dict

@inferless.request
class RequestObjects(BaseModel):
    prompt: str = Field(default="a horse near a beach")


@inferless.response
class ResponseObjects(BaseModel):
    generated_txt: str = Field(default='Test output')

class InferlessPythonModel:

    # replace ##task_type## and ##huggingface_name## with appropriate values
    def initialize(self):
        self.generator = pipeline("text-generation", model="EleutherAI/gpt-neo-125M",device=0)

    # inputs is a dictonary where the keys are input names and values are actual input data
    # e.g. in the below code the input name is prompt 
    # The output generated by the infer function should be a dictonary where keys are output names and values are actual output data
    # e.g. in the below code the output name is generated_txt
    def infer(self, inputs):
        print("we came inside infer", flush=True)
        prompt = inputs.prompt
        pipeline_output = self.generator(prompt, do_sample=True, min_length=50)
        generated_txt = pipeline_output[0]["generated_text"]
        generateObject = ResponseObjects(generated_txt = generated_txt)
        return generateObject

    # perform any cleanup activity here
    def finalize(self,args):
        self.pipe = None
